# Optimization Definition

Optimization in neural networks is the process of adjusting the model's parameters—typically the weights and biases—to minimize the error between predicted outputs and actual targets. This is done by minimizing a loss function, which quantifies how far off the predictions are from the ground truth.
