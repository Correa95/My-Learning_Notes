# Optimization Definition

Optimization in neural networks is the process of adjusting the model's parameters—typically the weights and biases—to minimize the error between predicted outputs and actual targets. This is done by minimizing a loss function, which quantifies how far off the predictions are from the ground truth.

⚙️ What Is an Optimization Method?
An optimization method (or optimizer) is an algorithm that updates the parameters of the neural network during training to reduce the loss. It uses gradients computed via backpropagation to guide these updates.
