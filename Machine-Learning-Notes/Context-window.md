🧠 What Is a Context Window?
The context window refers to the amount of text (or tokens) a model can "see" and consider at once when generating a response. Think of it like a memory span or a sliding window over a conversation or document.

- It includes your prompt, previous messages, and any relevant information.
- The model uses this window to understand what’s going on and generate coherent, relevant output.

📏 How Big Is It?
The size of the context window depends on the model architecture. For example: | Model Type | Typical Context Window | |-------------------|------------------------| | GPT-3 | ~2,048 tokens | | GPT-3.5 | ~4,096 tokens | | GPT-4 (some versions) | Up to 128,000 tokens |
🔹 One token is roughly 4 characters or ¾ of a word in English.
