{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7c64c519",
   "metadata": {},
   "source": [
    "Building a Energy Efficiency model\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "ee15b4a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "url = \"https://raw.githubusercontent.com/StephenElston/DataScience350/master/Lecture1/EnergyEfficiencyData.csv\"\n",
    "df = pd.read_csv(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "7f10fbf1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Relative Compactness</th>\n",
       "      <th>Surface Area</th>\n",
       "      <th>Wall Area</th>\n",
       "      <th>Roof Area</th>\n",
       "      <th>Overall Height</th>\n",
       "      <th>Orientation</th>\n",
       "      <th>Glazing Area</th>\n",
       "      <th>Glazing Area Distribution</th>\n",
       "      <th>Heating Load</th>\n",
       "      <th>Cooling Load</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.98</td>\n",
       "      <td>514.5</td>\n",
       "      <td>294.0</td>\n",
       "      <td>110.25</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>15.55</td>\n",
       "      <td>21.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.98</td>\n",
       "      <td>514.5</td>\n",
       "      <td>294.0</td>\n",
       "      <td>110.25</td>\n",
       "      <td>7.0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>15.55</td>\n",
       "      <td>21.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.98</td>\n",
       "      <td>514.5</td>\n",
       "      <td>294.0</td>\n",
       "      <td>110.25</td>\n",
       "      <td>7.0</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>15.55</td>\n",
       "      <td>21.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.98</td>\n",
       "      <td>514.5</td>\n",
       "      <td>294.0</td>\n",
       "      <td>110.25</td>\n",
       "      <td>7.0</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>15.55</td>\n",
       "      <td>21.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.90</td>\n",
       "      <td>563.5</td>\n",
       "      <td>318.5</td>\n",
       "      <td>122.50</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>20.84</td>\n",
       "      <td>28.28</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Relative Compactness  Surface Area  Wall Area  Roof Area  Overall Height  \\\n",
       "0                  0.98         514.5      294.0     110.25             7.0   \n",
       "1                  0.98         514.5      294.0     110.25             7.0   \n",
       "2                  0.98         514.5      294.0     110.25             7.0   \n",
       "3                  0.98         514.5      294.0     110.25             7.0   \n",
       "4                  0.90         563.5      318.5     122.50             7.0   \n",
       "\n",
       "   Orientation  Glazing Area  Glazing Area Distribution  Heating Load  \\\n",
       "0            2           0.0                          0         15.55   \n",
       "1            3           0.0                          0         15.55   \n",
       "2            4           0.0                          0         15.55   \n",
       "3            5           0.0                          0         15.55   \n",
       "4            2           0.0                          0         20.84   \n",
       "\n",
       "   Cooling Load  \n",
       "0         21.33  \n",
       "1         21.33  \n",
       "2         21.33  \n",
       "3         21.33  \n",
       "4         28.28  "
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7640a65",
   "metadata": {},
   "source": [
    " ‚úÖ 1. Step one of creating the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "fca1aa8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mathe\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\layers\\core\\dense.py:92: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    }
   ],
   "source": [
    " \n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers \n",
    "\n",
    "model = keras.Sequential([\n",
    "\n",
    "    layers.Dense(units=64, activation=\"relu\", input_shape=[8]),\n",
    "    layers.Dense(units=64, activation=\"relu\"),\n",
    "    layers.Dense(units=64, activation=\"relu\"),\n",
    "    layers.Dense(units=2)\n",
    "])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "419bccb8",
   "metadata": {},
   "source": [
    " ‚úÖ 2. Compile the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27323a6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ‚úÖ 2. Compile the Model\n",
    "# Before training, you need to tell Keras:\n",
    "# What loss function to optimize\n",
    "# What optimizer to use\n",
    "# What metrics to monitor\n",
    "# For a regression task (predicting continuous values):\n",
    "model.compile(\n",
    "    optimizer=\"adam\",            # Adaptive optimizer\n",
    "    loss=\"mse\",                  # Mean Squared Error for regression\n",
    "    metrics=[\"mae\"]              # Mean Absolute Error as performance metric\n",
    ")\n",
    "#üîç Breakdown of Parameters\n",
    "\n",
    "#‚úÖ optimizer=\"adam\"\n",
    "#1 Adam stands for Adaptive Moment Estimation\n",
    "#2 it‚Äôs one of the most popular and effective optimizers\n",
    "\n",
    "#Combines benefits of:\n",
    "#1 Momentum (like SGD with memory)\n",
    "#2 Adaptive learning rate (like RMSProp)\n",
    "#3 Automatically adjusts the learning rate for each parameter\n",
    "#‚ö° In short: Adam helps your model learn faster and more reliably than standard SGD.\n",
    "\n",
    "#‚úÖ metrics=[\"mae\"] (Mean Absolute Error)\n",
    "#1 MAE stands for Mean Absolute Error:\n",
    "# FORMULA MAE = 1/n ‚àë y true - y pred\n",
    "#2 Unlike MSE, it treats all errors equally (no squaring)\n",
    "#3 Gives a more human-interpretable measure ‚Äî \"on average, the model is off by ___ units\"\n",
    "\n",
    "#üí° You monitor MAE during training to see if the model is improving in a way that makes intuitive sense.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9775016",
   "metadata": {},
   "source": [
    "üìä 3. Prepare Your Data\n",
    "Assuming you have your features X and target y from the energy dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "dee6f4df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Side Note X should be capitalize \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Define input features (X) and both outputs (y)\n",
    "X = df.iloc[:, 0:8]                   # first 8 columns as features   # 8 input features\n",
    "y = df[[\"Heating Load\", \"Cooling Load\"]] # regression target  # 2 targets as a DataFrame\n",
    "\n",
    "# Split into train and test data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Normalize inputs by scaling it to standardize it before feeding it to the model\n",
    "scaler= StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train) # Fit on training data\n",
    "# But that‚Äôs not ideal. You should only fit the scaler on your training data, then use transform on your test data. Why? Because fit_transform on test data leaks information from the test set into your preprocessing pipeline, which can lead to data leakage and overly optimistic model performance.\n",
    "X_test_scaled = scaler.transform(X_test) # Transform test data only\n",
    "# Using fit_transform on both sets means the scaler learns from both training and test data, which violates the principle of keeping test data unseen. This can skew your model evaluation and lead to misleading results.\n",
    "\n",
    "\n",
    "# Scale targets\n",
    "y_scaler = StandardScaler()\n",
    "y_train_scaled = y_scaler.fit_transform(y_train) # Fit on training data\n",
    "# But that‚Äôs not ideal. You should only fit the scaler on your training data, then use transform on your test data. Why? Because fit_transform on test data leaks information from the test set into your preprocessing pipeline, which can lead to data leakage and overly optimistic model performance.\n",
    "y_test_scaled = y_scaler.transform(y_test) # Transform test data only\n",
    "# Using fit_transform on both sets means the scaler learns from both training and test data, which violates the principle of keeping test data unseen. This can skew your model evaluation and lead to misleading results.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f474d112",
   "metadata": {},
   "source": [
    "üìà 5. Evaluate the Model and Make Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "23b4f4c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m5/5\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.0548 - mae: 0.8996\n",
      "Evaluation Results: [1.0548014640808105, 0.8996257781982422]\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step \n"
     ]
    }
   ],
   "source": [
    "\n",
    "results = model.evaluate(X_test_scaled, y_test_scaled)\n",
    "print(\"Evaluation Results:\", results)\n",
    "\n",
    "\n",
    "#üß† 1. Predict on Test Data (Still Scaled)\n",
    "y_pred_scaled = model.predict(X_test_scaled)                 # Predictions in scaled form\n",
    "# üîç What this does:\n",
    "#1 Takes your scaled input features (X_test_scaled)\n",
    "#2 Feeds them into the trained model to get predictions\n",
    "#3 The predictions are still scaled (in standard score format: mean = 0, std = 1)\n",
    "#4 The model learned to predict in this scaled format because you trained it on scaled y_train\n",
    "\n",
    "# üß† 2. Inverse Transform to Get Real-World Predictions\n",
    "y_pred = y_scaler.inverse_transform(y_pred_scaled)           # Back to real scale\n",
    "# üîç What this does:\n",
    "#1 Takes the scaled predictions and converts them back to the original scale of the target variables (Heating Load and Cooling Load)\n",
    "#2 It uses the same y_scaler that you used to scale y_train earlier\n",
    "#3 Now your predictions are in the real units: kWh/m¬≤\n",
    "\n",
    "# üí° Why This is Necessary:\n",
    "# You scaled the training targets (y_train) using StandardScaler, so:\n",
    "# The model learned to predict in this transformed format\n",
    "# Predictions must be inverse transformed to interpret them in the real world\n",
    "\n",
    "#If you skip the inverse transform step, you‚Äôll get wrong-looking predictions like -0.12 when the real answer is 16.47.\n",
    "\n",
    "#üîπ loss: 1.2113:\n",
    "#This is the Mean Squared Error (MSE) between your predicted values and actual values on the test set.\n",
    "#Since you trained the model to minimize \"mse\" (mean squared error), this is the primary loss metric.\n",
    "#Lower is better. It means that on average, the square of the prediction error is ~1.21 (in scaled units).\n",
    "\n",
    "#üîπ mae: 1.0056:\n",
    "#This is the Mean Absolute Error, a more interpretable metric.\n",
    "#It tells you that your model is off by ~1.00 unit (standardized) per prediction on average.\n",
    "#Again, this is in scaled units, so it's not in the real-world kWh/m¬≤ scale ‚Äî but it still shows strong performance.\n",
    "\n",
    "#üîπ Evaluation Results: [1.211263656616211, 1.0056190490722656]:\n",
    "#Same numbers as above, printed as a list:\n",
    "#results[0] ‚Üí loss (MSE)\n",
    "#results[1] ‚Üí MAE (mean absolute error)\n",
    "\n",
    "#üìå Summary Interpretation:\n",
    "#‚úÖ Your model is doing well:\n",
    "#On average, it makes a small error (~1 unit in scaled format)\n",
    "#Predictions are consistent and run quickly\n",
    "#When you inverse-transform the predictions, this typically translates to realistic heating and cooling load values with only ~1 unit error (which is excellent)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86ecb99c",
   "metadata": {},
   "source": [
    "‚úÖ 1. Print actual vs predicted values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "c7d2384a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m5/5\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step \n",
      "Predicted ‚Üí Heating: -0.35, Cooling: 0.22 | Actual ‚Üí Heating: 16.47, Cooling: 16.90\n",
      "Predicted ‚Üí Heating: -0.35, Cooling: 0.42 | Actual ‚Üí Heating: 13.17, Cooling: 16.39\n",
      "Predicted ‚Üí Heating: 0.11, Cooling: 0.70 | Actual ‚Üí Heating: 32.82, Cooling: 32.78\n",
      "Predicted ‚Üí Heating: -0.05, Cooling: 0.20 | Actual ‚Üí Heating: 41.32, Cooling: 46.23\n",
      "Predicted ‚Üí Heating: -0.17, Cooling: 0.08 | Actual ‚Üí Heating: 16.69, Cooling: 19.76\n",
      "Predictions shape: (154, 2)\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_test_scaled)\n",
    "\n",
    "for i in range(5):\n",
    "    heating_pred = y_pred[i][0]\n",
    "    cooling_pred = y_pred[i][1]\n",
    "    heating_true = y_test.values[i][0]\n",
    "    cooling_true = y_test.values[i][1]\n",
    "\n",
    "    print(f\"Predicted ‚Üí Heating: {heating_pred:.2f}, Cooling: {cooling_pred:.2f} | \"\n",
    "          f\"Actual ‚Üí Heating: {heating_true:.2f}, Cooling: {cooling_true:.2f}\")\n",
    "    \n",
    "#This shows:\n",
    "#The model predicted:\n",
    "#2 Heating Load: -0.10\n",
    "#3Cooling Load: -0.08\n",
    "\n",
    "#The actual value was:\n",
    "#1 Heating Load: 16.47\n",
    "#2 Cooling Load: 16.90\n",
    "\n",
    "print(\"Predictions shape:\", y_pred.shape)  # Should be (num_samples, 2)\n",
    "\n",
    "#This confirms:\n",
    "#1 Your test set has 154 samples\n",
    "#2 Each prediction has 2 values ‚Üí one for heating load, one for cooling load\n",
    "# So, your model is correctly set up to do multi-output regression ‚úÖ\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb27aadf",
   "metadata": {},
   "source": [
    "üíæ 8. Save the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3ee393f1",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241m.\u001b[39msave(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124menergy_model.h5\u001b[39m\u001b[38;5;124m\"\u001b[39m)  \u001b[38;5;66;03m# Save in HDF5 format\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m# You can later load it with:\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m load_model\n",
      "\u001b[1;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "model.save(\"energy_model.h5\")  # Save in HDF5 format\n",
    "# You can later load it with:\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "model = load_model(\"energy_model.h5\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83aadac1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
